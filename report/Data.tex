\documentclass[11pt]{article}
\usepackage{mypackages}
\begin{document}

\maketitle

\section{Data}\label{Data}

To train and test our actor-critic and advantage asynchronous actor-critic implementation we will use
the OpenAI Gym framework\cite{openAIGym}.
This framework provides an interface to 118 Atari 2600 games,
that can be used by developers to compare and test their reinforcement learning algorithms.

 
In the Atari enviroments there is always a finite \textit{action space} and continous \textit{state space}.
The state space is continous because a \textit{state} is represented as a RGB image - a screenshot - from a game
at the given time. The action space is finite because there is always a fixed amount of
actions available to the player in the OpenAI Gym framework.

Simulating an action in a game return information about the new state,
a \textit{reward} for taking this action and a \textit{binary signal} which indicate whether the 
game is done or not.
The reward is the score gained from transitioning to the new state and
it is not uncommon for this reward to be $0$ as many of the players actions do not produce immediate rewards.

\subsection{Cart-Pole}

Among a lot of other game types OpenAI gym also supports an interface
to the Cart-Pole problem.
A player can win the Cart-Pole game if he manages to balance a pole connected to the top of a moving cart for
200 consecutive frames.
The player loses if the pole moves more than 15 degrees from vertical in
either direction or if the cart exits the frame.

\begin{figure}[!h]
    \centering
    \fbox{\includegraphics[scale=0.5]{include/cartpole.png}}
    \caption{A frame from Cart-Pole.}
    \label{fig:cartpole}
\end{figure}

Unlike the Atari environments a state in Cart-Pole consits of only four elements - the position and velocity of the cart, and the
angle and angular velocity of the pole.
Each time step, corresponding to a new frame, the player has to chose between moving the cart to the right or to the left and it is not possible
to do nothing.
For every time step the pole doesn't move 15 degrees from vertical and
the cart stays inside the frame, the player is awarded a single point.

We will be using the Cart-Pole problem as a proof of concept for our actor-critic implementation and will
compare it to the A3C algorithm used on the same problem.
The reason for using the Cart-Pole problem is that it should be easier
to solve, because each state consists of fewer dimensions than a state
from an Atari game.


\subsection{Atari 2600 games}

A state in an Atari game is represented as a 3-dimensional matrix representing a
frame.
This means that instead of only taking 4 items into consideration when picking an action,
the player is now faced with a much more complex view. 
All of the games have the same resolution of $210 \times 160$ pixels.
Each pixel contains three channels corresponding to the red, green and blue intensities of the pixel.
\begin{figure}[!h]
    \centering
    \includegraphics[scale=0.35]{include/space_invaders_1.png}
    \caption{A raw RGB frame from \textit{Space Invaders}.}
    \label{fig:si}
\end{figure}

Using the raw Atari frames can be computationally demanding, so we have chosen
to preprocess our data as described in \cite{dqn}. 
The first step of the preprocessing is to reduce the amount of channels used to
represent the image.
To do this we gray-scale the RGB representation of the frames so that only a single channel is used.
In our approach, the gray-scaling calculates the relative luminance\cite{luminance} of each pixel
for which the formula is given in equation \ref{eq:lum}.
\begin{equation}\label{eq:lum}
    L(R, G, B) = 0.2126*R + 0.7152*G + 0.0722*B
\end{equation}

We further reduce the dimensions of the gray-scaled images by a downsampling.
We simply ignore every second pixel effectively halfing the resolution of the frames 
in both dimensions.
\begin{figure}[h!]
    \begin{subfigure}[t]{.5\textwidth}
        \centering
        \includegraphics[scale=0.35]{include/space_invaders_1_gray.png}
        \caption{The gray-scaled frame from figure \ref{fig:si}.}
        \label{fig:sig}
    \end{subfigure}
    \begin{subfigure}[t]{.5\textwidth}
        \centering
        \includegraphics[scale=0.35]{include/space_invaders_1_gray_resized.png}
        \caption{The result of resizing the gray-scaled frame from figure \ref{fig:sig}.}
        \label{fig:scanlike}
    \end{subfigure}
    \caption{The two steps of the preprocessing applied to the raw frame from figure \ref{fig:si}.}
\end{figure}


The final output of the preprocessing step is a $105 \times 80$ pixel gray-scaled
image.
After the data has been preprocessed it is computationally cheaper to extract the remaining
features than it would be to extract them from the raw Atari frames,
since the dimensions of input image have been significantly reduced.
The reason we can downsample the frames the way we have,
is due to an assumption about the structure of the input - that
little to no information is lost in the process, because no important objects vanish completely.

In the articles \cite{a3c} and \cite{dqn} one more preprocessingstep is performed.
Instead of only resizing the gray-scaled frames, they are also cropped to $84 \times 84$ images.
This is done to meet a condition in their implementation of 2d convolutions,
since they could only process square input\cite{dqn-nature}.
We will only be resizing the gray-scaled images and not be cropping,
since the cropping doesn't serve the same purpose in our project.
Another consideration is that if the images were to be cropped in the same manner,
the different structures of the games would lead to an unstable
result, meaning we would have to handcraft a cropping scheme for each game.

Due to the time limitations of this project we will only be testing our
implementation of the A3C algorithm on certain games.
Namely \textit{Pong}, \textit{Breakout}, \textit{Space Invaders} and
\textit{Pacman}.

\end{document}
